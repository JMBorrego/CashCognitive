{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b994c330",
   "metadata": {},
   "source": [
    "# Índice\n",
    "\n",
    "1. [Exploración inicial de características](#explo)\n",
    "1. [Variables de respuesta](#outcome)\n",
    "   1. [Datos faltantes](#nanout)\n",
    "1. [Variables independientes](#input)\n",
    "   1. [Correlaciones](#corr)\n",
    "   1. [Gestión de datos faltantes](#nan)\n",
    "   1. [Valores atípicos](#outlier)\n",
    "   1. [Reescalado de datos](#scale)\n",
    "1. [Resumen](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41fbe89",
   "metadata": {},
   "source": [
    "Notebook imitant:\n",
    "    https://towardsdatascience.com/causal-machine-learning-for-econometrics-causal-forests-5ab3aec825a7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b33a126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c4ce38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lectura de los datos brutos y división del dataset\n",
    "\n",
    "df = pd.read_stata('Cash_and_Childhood_Development_Replication/macoursetal_main.dta')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac4db177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"hogarid_old\",\"cp_old\",\"unique_05\", \"cpmom_06\" seran usats com a index\n",
    "df_out=df[[\"a5sscore_i_06\",\"a6smemory_p1_06\",\"a6smemory_p2_06\",\"a7a_delay_06\",\"a7b_delay_06\",\n",
    "        \"a7c_delay_06\",\"a7d_delay_06\",\"a9sgrossmotor_06\",\"height_06\",\"weight_06\",\"z_tvip_06\",\"z_social_06\",\n",
    "        \"z_language_06\",\"z_finmotor_06\",\"z_memory_06\",\"z_grmotor_06\",\"z_legmotor_06\",\"z_behavior_06\",\"z_height_06\",\n",
    "        \"z_weight_06\",\"z_all_06\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8452d06e",
   "metadata": {},
   "source": [
    "# Income variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4e8d4",
   "metadata": {},
   "source": [
    "#2-6: Treiem variables:\n",
    "\n",
    "\"hogarid_old\",\"cp_old\", \"unique_05\", \"itt_all_i\", \"TREAT1\",\"TREAT2\",\"TREAT3\",\"TREAT4\", \"com_tvip_05\", \"com_control_05\"\n",
    ", \"com_notvip\", \"sample06\",\"weighted_05\", ,\"itt_i\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16fa80e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[[\"hogarid_old\",\"s1age_head_05\",\"s1hhsize_05\",\"s1hhsz_undr5_05\",\"s1hhsz_5_14_05\",\n",
    "        \"s1hhsz_15_24_05\",\"s1hhsz_25_64_05\",\"s1hhsz_65plus_05\",\"s1male_head_05\",\"s2mother_inhs_05\",\"s3ap5_rooms_h_05\",\n",
    "        \"s3ap23_stime_h_05\",\"s3ap24_htime_h_05\",\"s3ap25_hqtime_h_05\",\"s3atoilet_hh_05\",\"s3awater_access_hh_05\",\n",
    "        \"s3aelectric_hh_05\",\"s4p6_vitamina_i_05\",\"s4p7_parasite_i_05\",\"s11ownland_hh_05\",\"cons_food_pc_05\",\"cons_tot_pc_05\",\n",
    "        \"height_05\",\"a10whz_05\",\"weight_05\",\"yrsedfath\",\"age_transfer\",\"bweight\",\n",
    "        \"s4p7_parasite_i_06\",\"T\",\"male\",\"ed_mom\",\"MUN1\",\"MUN2\",\"MUN3\",\"MUN4\",\n",
    "        \"MUN5\",\"MUN6\",\"com_haz_05\",\"com_waz_05\",\"com_vit_05\",\"com_deworm_05\",\n",
    "        \"vitamiron_06\", \"propfood_05\",\"prstap_f_05\",\"pranimalprot_f_05\",\"prfruitveg_f_05\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c88df450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuari\\AppData\\Local\\Temp\\ipykernel_8012\\2300806653.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df1.rename(columns = {'T':'tr'}, inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df1.rename(columns = {'T':'tr'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7179548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fem una copia del df\n",
    "def copy_df(df):\n",
    "   return df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b51b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminem individus amb >delta*100% columnes buides\n",
    "def drop_ind_missing(df, delta):\n",
    "    thresh = len(df.columns)*delta\n",
    "    df.dropna(axis=0, thresh=thresh, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e905b250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminem individus amb age transfer<age\n",
    "def drop_out_missing(df, age=-11):\n",
    "    nan_rows=df[df.age_transfer<age].index\n",
    "    df.drop(nan_rows, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e98fd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorical to ordinal\n",
    "def ordinal(df, cols):\n",
    "    enc = OrdinalEncoder()\n",
    "    enc.fit(df[cols])\n",
    "    df[cols] = enc.transform(df[cols])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12652e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imputem NaNs\n",
    "\n",
    "#imputem mitjanes\n",
    "def mean_imputer(df, cols):\n",
    "    for col in cols:\n",
    "        df[col].fillna(df[col].mean(), inplace=True)\n",
    "    return df\n",
    "\n",
    "#imputem el valor més frequent de la columna dintre el hh\n",
    "def hh_mf_imputer(df,cols):\n",
    "    index=df.index\n",
    "    for col in cols:\n",
    "        col_hh=[df[df.hogarid_old==familia][[col,\"age_transfer\"]].sort_values(by=['age_transfer'])[col]\n",
    "                .values for familia in df.hogarid_old]\n",
    "        for i in range(len(index)):\n",
    "               if np.isnan(df[col][index[i]]):\n",
    "                    non_nan_len=np.count_nonzero(~np.isnan(col_hh[i]))\n",
    "                    if(non_nan_len!=0):\n",
    "                        vals,counts = np.unique(col_hh[i], return_counts=True)\n",
    "                        ind = np.argmax(counts)\n",
    "                        df.loc[index[i],col]=vals[ind]\n",
    "    return df             \n",
    "                            \n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3ab3651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminem outliers\n",
    "\n",
    "def outlier_removal(df, cols):\n",
    "    outlier_threshold = []\n",
    "    for col in cols:\n",
    "            q3 = np.nanpercentile(df[col], 75)\n",
    "            q1 = np.nanpercentile(df[col], 25)\n",
    "            iqr = q3 - q1\n",
    "            out_low = q1 - 3*iqr\n",
    "            out_high = q3 + 3*iqr\n",
    "            outlier_threshold.append([out_low, out_high])\n",
    "    outliers_indexs=[]\n",
    "    for col,k in zip(cols,range(len(cols))):\n",
    "        #outliers_indexs_in_col=[]\n",
    "        for i in df[col].index:\n",
    "            if df[col][i]<outlier_threshold[k][0] or df[col][i]>outlier_threshold[k][1]:\n",
    "                outliers_indexs.append(i)\n",
    "        #outliers_indexs.append(outliers_indexs_in_col)\n",
    "    return df.drop(list(set(outliers_indexs)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f97cfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols):\n",
    "    Nscaler = MinMaxScaler()\n",
    "\n",
    "    Nscaler.fit(df[cols])\n",
    "    df[cols] = Nscaler.transform(df[cols])\n",
    "    \n",
    "    return df\n",
    "\n",
    "def standardize(df, cols):\n",
    "    Sscaler = StandardScaler()\n",
    "\n",
    "    Sscaler.fit(df[cols])\n",
    "    df[cols] = Sscaler.transform(df[cols])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3987cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "mean_cols=[\"bweight\", \"height_05\", \"a10whz_05\", \"weight_05\"]\n",
    "hh_mf_cols=[\"s1age_head_05\",\"s1hhsize_05\",\"s1hhsz_undr5_05\",\"s1hhsz_5_14_05\",\"s1hhsz_15_24_05\",\"s1hhsz_25_64_05\",\n",
    "            \"s1hhsz_65plus_05\",\"s1male_head_05\",\"s2mother_inhs_05\",\"s3ap5_rooms_h_05\",\"s3atoilet_hh_05\",\n",
    "            \"s3awater_access_hh_05\",\"s3aelectric_hh_05\",\"s11ownland_hh_05\",\"s4p7_parasite_i_06\",\"ed_mom\",\"vitamiron_06\",\n",
    "           \"s4p6_vitamina_i_05\", \"s4p7_parasite_i_05\", \"cons_food_pc_05\", \"yrsedfath\", \"propfood_05\", \"prstap_f_05\"\n",
    "            ,  \"pranimalprot_f_05\",  \"prfruitveg_f_05\"]\n",
    "\n",
    "categorical_cols=df1.select_dtypes(exclude=[\"number\",\"bool_\",\"object_\"]).columns\n",
    "outlier_cols=[\"pranimalprot_f_05\", \"bweight\", \"prfruitveg_f_05\"]\n",
    "\n",
    "normal_cols =[\"height_05\",\"a10whz_05\",\"weight_05\",\"com_haz_05\",\"com_waz_05\"]\n",
    "\n",
    "Nnormal_cols = ['s1age_head_05', 's3ap23_stime_h_05', 's3ap24_htime_h_05', 's3ap25_hqtime_h_05', 'cons_food_pc_05', \n",
    "                'cons_tot_pc_05', 'yrsedfath','age_transfer', 'bweight', 'ed_mom', 'com_tvip_05', 'com_control_05']\n",
    "\n",
    "\n",
    "cleaned_df=(df1.pipe(copy_df)\n",
    "            .pipe(drop_ind_missing, 0.8)\n",
    "            .pipe(drop_out_missing)\n",
    "            .pipe(ordinal, categorical_cols)\n",
    "            .pipe(hh_mf_imputer, hh_mf_cols)\n",
    "            .pipe(mean_imputer, mean_cols+hh_mf_cols)\n",
    "            .pipe(outlier_removal, outlier_cols) #outliers\n",
    "            .pipe(standardize, normal_cols) #estandaritzacio\n",
    "            .pipe(normalize, Nnormal_cols)) #normalitzacio\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee7503c",
   "metadata": {},
   "source": [
    "GUARDAR DF COMO PICKLE RICK"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
